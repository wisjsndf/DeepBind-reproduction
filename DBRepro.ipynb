{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4fba772",
   "metadata": {},
   "source": [
    "# DeepBind Reproduction\n",
    "## PBM Dataset\n",
    "### PBM 数据集  \n",
    "<b> (1)sequences.tsv.gz </b>  \n",
    "一列或多列的tsv,每行对应一个短序列(一个probe)   \n",
    "<b> (2)targets.tsv.gz </b>  \n",
    "对于sequences.tsv.gz的强度表，每一行对应一个probe,每一列对应一个TF  \n",
    "<b> (3)tfids.txt </b>  \n",
    "一行一个TFid  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dd9dfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found TF ids (first 20): ['TF_1', 'TF_2', 'TF_3', 'TF_4', 'TF_5', 'TF_6', 'TF_7', 'TF_8', 'TF_9', 'TF_10', 'TF_11', 'TF_12', 'TF_13', 'TF_14', 'TF_15', 'TF_16', 'TF_17', 'TF_18', 'TF_19', 'TF_20']\n",
      "Total TF columns: 86\n",
      "sequences shape: (80857, 3)\n",
      "first rows:\n",
      "          0               1                                         2\n",
      "0  Fold ID        Event ID                                       seq\n",
      "1        B  MEreverse14075  TAAAACTATGAGGAAGGATTCAGGGTCGGACAGTGCCTGT\n",
      "2        B  MEforward19438  CTTATGATCAGAAGCGGCTAGGTGTATTACATGTCCCTGT\n",
      "3        B  MEforward19439  CCGCCGTAGGCCCCGAAACAGTACCAGACATGTAACCTGT\n",
      "4        B  MEforward19436  GACCAAACGAGTCCTAGGATTCCAAGCGTTACGACCCTGT\n",
      "targets shape: (80856, 86)\n",
      "targets columns: Index(['TF_40', 'TF_41', 'TF_42', 'TF_43', 'TF_44', 'TF_45', 'TF_46', 'TF_47',\n",
      "       'TF_48', 'TF_49', 'TF_7', 'TF_6', 'TF_5', 'TF_4', 'TF_3', 'TF_2',\n",
      "       'TF_1', 'TF_9', 'TF_8', 'TF_35'],\n",
      "      dtype='object')\n",
      "first rows:\n",
      "          TF_40         TF_41        TF_42        TF_43        TF_44  \\\n",
      "0   823.914118  12702.625538  2124.023125  2314.305782  1474.888697   \n",
      "1  1307.840222   4316.426121  2554.658908  3415.320661  3408.586803   \n",
      "2  1188.353499   3436.803941  2088.909658  3708.324021  2219.741833   \n",
      "3  1806.103795   6531.268855  2406.186212  3601.204703  2828.415329   \n",
      "4  1417.411525   3951.243575  2581.309532  3375.884699  2764.716964   \n",
      "\n",
      "         TF_45        TF_46         TF_47        TF_48         TF_49  ...  \\\n",
      "0  1131.785521  4597.003319  14589.890994  1556.951404  34180.775942  ...   \n",
      "1  1697.342725  5272.763446  22903.130555  2181.551097  10000.297243  ...   \n",
      "2  1571.646567  6225.376501  13858.014077  1971.053716  18800.025304  ...   \n",
      "3  2746.861783  5810.104650  25701.749693  2191.273065  19213.880658  ...   \n",
      "4  1806.919566  5033.976283  26364.859152  2311.790793  16139.097553  ...   \n",
      "\n",
      "          C_19         C_18         C_15         C_14          C_17  \\\n",
      "0  1651.254953  1242.303363   724.105850  3184.883349   8935.394363   \n",
      "1  3505.604759  2516.000120  1640.114829  3463.713253  19535.468264   \n",
      "2  3270.572883  1693.419147   997.792996  3196.992198  16695.027604   \n",
      "3  2701.555739  2059.614815  1432.163042  4927.163643  18896.765835   \n",
      "4  2457.214141  1901.709222  1672.531034  3877.787322  14699.253953   \n",
      "\n",
      "           C_16          C_11          C_10          C_13         C_12  \n",
      "0  12689.558779   4102.312624    505.126184  12946.381724  1313.790253  \n",
      "1  18006.721690   6890.427794   1402.597000  38309.856355  3024.107809  \n",
      "2  14486.992627  13517.968701  10680.866586  25648.825592  2675.530918  \n",
      "3  18784.043322   8608.167421   4624.044391  23651.726053  3679.449867  \n",
      "4  17119.871513   8995.328144  12641.425965  27999.405431  3128.844808  \n",
      "\n",
      "[5 rows x 86 columns]\n",
      "npz keys: ['A', 'B']\n",
      "A (40330,) float64\n",
      "sample: [2654.937923  3041.923394  2373.6399365 1685.173616  3740.6147665]\n",
      "B (40526,) float64\n",
      "sample: [2641.988164  4170.2475    3699.8877625 4622.249988  3877.787322 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27875/377958945.py:29: UserWarning: Reading `.npy` or `.npz` file required additional header parsing as it was created on Python 2. Save the file again to speed up loading and avoid this warning.\n",
      "  arr = npz[k]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "# 1) 看 tfids.txt\n",
    "with open('../DeepBind/data/dream5/pbm/tfids.txt', 'r') as f:\n",
    "    tfids = [ln.strip() for ln in f if ln.strip()]\n",
    "print(\"Found TF ids (first 20):\", tfids[:20])\n",
    "print(\"Total TF columns:\", len(tfids))\n",
    "\n",
    "# 2) 读 sequences.tsv.gz（如果每行是序列）\n",
    "seqs = pd.read_csv('../DeepBind/data/dream5/pbm/sequences.tsv.gz', sep='\\t', header=None, compression='gzip', engine='python')\n",
    "print(\"sequences shape:\", seqs.shape)\n",
    "print(\"first rows:\\n\", seqs.head())\n",
    "\n",
    "# 常见：如果只有一列，序列在第0列\n",
    "# seqs[0].head()\n",
    "\n",
    "# 3) 读 targets.tsv.gz（检查列名/形状）\n",
    "targets = pd.read_csv('../DeepBind/data/dream5/pbm/targets.tsv.gz', sep='\\t', header=0, compression='gzip', engine='python')\n",
    "print(\"targets shape:\", targets.shape)\n",
    "print(\"targets columns:\", targets.columns[:20])\n",
    "print(\"first rows:\\n\", targets.head())\n",
    "\n",
    "# 4) 检查 probe_biases.npz\n",
    "npz = np.load('../DeepBind/data/dream5/pbm/probe_biases.npz', allow_pickle=True)\n",
    "print(\"npz keys:\", list(npz.keys()))\n",
    "for k in npz:\n",
    "    arr = npz[k]\n",
    "    print(k, arr.shape, arr.dtype)\n",
    "    print(\"sample:\", arr[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084322d",
   "metadata": {},
   "source": [
    "用pbm.py处理pbm数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e14616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb shape: torch.Size([4, 4, 36])\n",
      "yb shape: torch.Size([4])\n",
      "yb: tensor([ 484.5081, 1137.2778,  982.1860, 1511.8501])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data.pbm import PBMDataset\n",
    "import torch\n",
    "\n",
    "seq_file = '../DeepBind/data/dream5/pbm/sequences.tsv.gz'\n",
    "tgt_file = '../DeepBind/data/dream5/pbm/targets.tsv.gz'\n",
    "tf_col = 'TF_1'\n",
    "\n",
    "dataset = PBMDataset(seq_file, tgt_file, tf_col=tf_col, max_len=36)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "for xb, yb in loader:\n",
    "    print(\"xb shape:\", xb.shape)\n",
    "    print(\"yb shape:\", yb.shape)\n",
    "    print(\"yb:\", yb)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55af19c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available TFs: ['TF_1', 'TF_2', 'TF_3', 'TF_4', 'TF_5', 'TF_6', 'TF_7', 'TF_8', 'TF_9', 'TF_10', 'TF_11', 'TF_12', 'TF_13', 'TF_14', 'TF_15', 'TF_16', 'TF_17', 'TF_18', 'TF_19', 'TF_20', 'TF_21', 'TF_22', 'TF_23', 'TF_24', 'TF_25', 'TF_26', 'TF_27', 'TF_28', 'TF_29', 'TF_30', 'TF_31', 'TF_32', 'TF_33', 'TF_34', 'TF_35', 'TF_36', 'TF_37', 'TF_38', 'TF_39', 'TF_40', 'TF_41', 'TF_42', 'TF_43', 'TF_44', 'TF_45', 'TF_46', 'TF_47', 'TF_48', 'TF_49', 'TF_50']\n"
     ]
    }
   ],
   "source": [
    "with open('../DeepBind/data/dream5/pbm/tfids.txt') as f:\n",
    "    tfids = [l.strip() for l in f if l.strip()]\n",
    "    print(\"Available TFs:\", tfids[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe0b449",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=-0.0041, std=0.9680, unique=[-1.6008122 -1.5992286 -1.5940433 -1.5902673 -1.5876826 -1.585011\n",
      " -1.5823246 -1.5776969 -1.577265  -1.5771194]\n",
      " preds : mean=0.0820, std=0.0000, min=0.0820, max=0.0820\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=-0.0041, std=0.9680, unique=[-1.6008122 -1.5992286 -1.5940433 -1.5902673 -1.5876826 -1.585011\n",
      " -1.5823246 -1.5776969 -1.577265  -1.5771194]\n",
      " preds : mean=0.0161, std=0.0000, min=0.0161, max=0.0161\n",
      "[Calib 01/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.027563155364944907, 'momentum': 0.9858565380848294, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.1203730030100611e-05, 'init_scale_nn': 0.003484547305867, 'weight_decay_motifs': 3.884834472354271e-09, 'weight_decay_nn': 1.2609275325509064e-05, 'dropout_rate': 0.5} CV_score=0.1681\n",
      "[Calib 02/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.029603820055128814, 'momentum': 0.9678458171389729, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.3120067640477764e-05, 'init_scale_nn': 0.006989121280895438, 'weight_decay_motifs': 5.262926788691343e-09, 'weight_decay_nn': 4.949285643966314e-05, 'dropout_rate': 0.5} CV_score=0.4973\n",
      "[Calib 03/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.0020756002660461677, 'momentum': 0.9884575747528715, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 7.747473381408426e-05, 'init_scale_nn': 0.0002180336065688407, 'weight_decay_motifs': 2.839690411216508e-05, 'weight_decay_nn': 6.338260082050596e-09, 'dropout_rate': 0.0} CV_score=0.6792\n",
      "[Calib 04/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.004308160466206715, 'momentum': 0.9823584335200372, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0007783136325520854, 'init_scale_nn': 4.631264701438715e-05, 'weight_decay_motifs': 1.3609093921059509e-08, 'weight_decay_nn': 1.5461045105654734e-10, 'dropout_rate': 0.0} CV_score=0.6341\n",
      "[Calib 05/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.0017849640898443134, 'momentum': 0.95097975518888, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.5205971049766103e-07, 'init_scale_nn': 0.0001988499659933053, 'weight_decay_motifs': 3.587062720993371e-08, 'weight_decay_nn': 2.3966544838032185e-07, 'dropout_rate': 0.25} CV_score=0.6553\n",
      "[Calib 06/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.002559137471198451, 'momentum': 0.964806186787171, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.9383208619320652e-06, 'init_scale_nn': 0.0006059662577973105, 'weight_decay_motifs': 0.000696214790285433, 'weight_decay_nn': 2.7328245542630575e-08, 'dropout_rate': 0.25} CV_score=0.6540\n",
      "[Calib 07/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.01276526321002485, 'momentum': 0.964533278197854, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 6.251136602778478e-06, 'init_scale_nn': 1.858031513915266e-05, 'weight_decay_motifs': 4.3977565601268976e-14, 'weight_decay_nn': 3.8165278244662606e-05, 'dropout_rate': 0.0} CV_score=0.5640\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0114, std=1.0463, unique=[-1.6177288 -1.6081908 -1.6076684 -1.6045547 -1.6008122 -1.5994041\n",
      " -1.5992286 -1.5940433 -1.5937419 -1.593559 ]\n",
      " preds : mean=0.2199, std=0.0000, min=0.2199, max=0.2199\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0114, std=1.0463, unique=[-1.6177288 -1.6081908 -1.6076684 -1.6045547 -1.6008122 -1.5994041\n",
      " -1.5992286 -1.5940433 -1.5937419 -1.593559 ]\n",
      " preds : mean=-0.0733, std=0.0000, min=-0.0733, max=-0.0733\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0114, std=1.0463, unique=[-1.6177288 -1.6081908 -1.6076684 -1.6045547 -1.6008122 -1.5994041\n",
      " -1.5992286 -1.5940433 -1.5937419 -1.593559 ]\n",
      " preds : mean=-0.0510, std=0.0000, min=-0.0510, max=-0.0510\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0114, std=1.0463, unique=[-1.6177288 -1.6081908 -1.6076684 -1.6045547 -1.6008122 -1.5994041\n",
      " -1.5992286 -1.5940433 -1.5937419 -1.593559 ]\n",
      " preds : mean=0.0093, std=0.0000, min=0.0093, max=0.0093\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=-0.0104, std=0.9511, unique=[-1.6134442 -1.6124986 -1.6087955 -1.6039681 -1.6030033 -1.6028873\n",
      " -1.6027195 -1.5947446 -1.5826494 -1.5817671]\n",
      " preds : mean=-0.0603, std=0.0000, min=-0.0603, max=-0.0603\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=-0.0104, std=0.9511, unique=[-1.6134442 -1.6124986 -1.6087955 -1.6039681 -1.6030033 -1.6028873\n",
      " -1.6027195 -1.5947446 -1.5826494 -1.5817671]\n",
      " preds : mean=-0.0342, std=0.0000, min=-0.0342, max=-0.0342\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=-0.0104, std=0.9511, unique=[-1.6134442 -1.6124986 -1.6087955 -1.6039681 -1.6030033 -1.6028873\n",
      " -1.6027195 -1.5947446 -1.5826494 -1.5817671]\n",
      " preds : mean=0.1250, std=0.0000, min=0.1250, max=0.1250\n",
      "[Calib 08/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.012006239910448918, 'momentum': 0.9891459418331734, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.00027138954459629766, 'init_scale_nn': 0.0003197390619410733, 'weight_decay_motifs': 4.4143771275839035e-09, 'weight_decay_nn': 0.00010824179245894717, 'dropout_rate': 0.25} CV_score=0.5810\n",
      "[Calib 09/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.0029976077646241463, 'momentum': 0.9656760758401223, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0006370685951665188, 'init_scale_nn': 0.0019708333207471224, 'weight_decay_motifs': 8.911799121353853e-12, 'weight_decay_nn': 9.08648979840617e-08, 'dropout_rate': 0.0} CV_score=0.6692\n",
      "[Calib 10/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.001098673694545384, 'momentum': 0.9769495202472442, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 6.192854347326676e-06, 'init_scale_nn': 0.0003198992641581308, 'weight_decay_motifs': 8.825466480010853e-14, 'weight_decay_nn': 1.7260834394766688e-09, 'dropout_rate': 0.5} CV_score=0.6695\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=0.0045, std=0.9822, unique=[-1.6131452 -1.6124986 -1.6087955 -1.6068466 -1.6039681 -1.6030033\n",
      " -1.6008122 -1.5992286 -1.593559  -1.5876826]\n",
      " preds : mean=-0.0264, std=0.0000, min=-0.0264, max=-0.0264\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=0.0045, std=0.9822, unique=[-1.6131452 -1.6124986 -1.6087955 -1.6068466 -1.6039681 -1.6030033\n",
      " -1.6008122 -1.5992286 -1.593559  -1.5876826]\n",
      " preds : mean=-0.0773, std=0.0000, min=-0.0773, max=-0.0773\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=0.0045, std=0.9822, unique=[-1.6131452 -1.6124986 -1.6087955 -1.6068466 -1.6039681 -1.6030033\n",
      " -1.6008122 -1.5992286 -1.593559  -1.5876826]\n",
      " preds : mean=0.0217, std=0.0000, min=0.0217, max=0.0217\n",
      "[Calib 11/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.01591432480150043, 'momentum': 0.9696932530393407, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.0811662812163932e-07, 'init_scale_nn': 5.112301953281905e-05, 'weight_decay_motifs': 2.1599953816081472e-13, 'weight_decay_nn': 1.7486655632895372e-07, 'dropout_rate': 0.25} CV_score=0.5965\n",
      "[Calib 12/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.004708575308761038, 'momentum': 0.9789582172007436, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 2.0275944453959436e-07, 'init_scale_nn': 1.062677837056879e-05, 'weight_decay_motifs': 1.980765198623674e-06, 'weight_decay_nn': 7.679847458553305e-07, 'dropout_rate': 0.5} CV_score=0.6195\n",
      "[Calib 13/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.003231072010900085, 'momentum': 0.9823188078608179, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.00016909914215174166, 'init_scale_nn': 0.005503525909893539, 'weight_decay_motifs': 1.7728506272305663e-06, 'weight_decay_nn': 2.925576955975853e-10, 'dropout_rate': 0.25} CV_score=0.6597\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0004, std=0.9610, unique=[-1.649212  -1.6391003 -1.6134442 -1.6068466 -1.6028873 -1.6027195\n",
      " -1.6008122 -1.5996478 -1.5994041 -1.5940433]\n",
      " preds : mean=-0.0229, std=0.0000, min=-0.0229, max=-0.0229\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0004, std=0.9610, unique=[-1.649212  -1.6391003 -1.6134442 -1.6068466 -1.6028873 -1.6027195\n",
      " -1.6008122 -1.5996478 -1.5994041 -1.5940433]\n",
      " preds : mean=-0.1162, std=0.0000, min=-0.1162, max=-0.1162\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0004, std=0.9610, unique=[-1.649212  -1.6391003 -1.6134442 -1.6068466 -1.6028873 -1.6027195\n",
      " -1.6008122 -1.5996478 -1.5994041 -1.5940433]\n",
      " preds : mean=0.0121, std=0.0000, min=0.0121, max=0.0121\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0004, std=0.9610, unique=[-1.649212  -1.6391003 -1.6134442 -1.6068466 -1.6028873 -1.6027195\n",
      " -1.6008122 -1.5996478 -1.5994041 -1.5940433]\n",
      " preds : mean=-0.2491, std=0.0000, min=-0.2491, max=-0.2491\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0004, std=0.9610, unique=[-1.649212  -1.6391003 -1.6134442 -1.6068466 -1.6028873 -1.6027195\n",
      " -1.6008122 -1.5996478 -1.5994041 -1.5940433]\n",
      " preds : mean=-0.0671, std=0.0000, min=-0.0671, max=-0.0671\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=-0.0035, std=0.9839, unique=[-1.6177288 -1.6087955 -1.6081908 -1.6076684 -1.6045547 -1.6039681\n",
      " -1.577265  -1.5771685 -1.5771194 -1.5744097]\n",
      " preds : mean=-0.0210, std=0.0000, min=-0.0210, max=-0.0210\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=-0.0035, std=0.9839, unique=[-1.6177288 -1.6087955 -1.6081908 -1.6076684 -1.6045547 -1.6039681\n",
      " -1.577265  -1.5771685 -1.5771194 -1.5744097]\n",
      " preds : mean=-0.0458, std=0.0000, min=-0.0458, max=-0.0458\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=-0.0035, std=0.9839, unique=[-1.6177288 -1.6087955 -1.6081908 -1.6076684 -1.6045547 -1.6039681\n",
      " -1.577265  -1.5771685 -1.5771194 -1.5744097]\n",
      " preds : mean=-0.0215, std=0.0000, min=-0.0215, max=-0.0215\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=-0.0035, std=0.9839, unique=[-1.6177288 -1.6087955 -1.6081908 -1.6076684 -1.6045547 -1.6039681\n",
      " -1.577265  -1.5771685 -1.5771194 -1.5744097]\n",
      " preds : mean=-0.0015, std=0.0000, min=-0.0015, max=-0.0015\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=-0.0035, std=0.9839, unique=[-1.6177288 -1.6087955 -1.6081908 -1.6076684 -1.6045547 -1.6039681\n",
      " -1.577265  -1.5771685 -1.5771194 -1.5744097]\n",
      " preds : mean=-0.1081, std=0.0000, min=-0.1081, max=-0.1081\n",
      "[Calib 14/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.044218046531328235, 'momentum': 0.9643863074384043, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 5.640447887198347e-07, 'init_scale_nn': 0.0003179637241090179, 'weight_decay_motifs': 1.5940057862631183e-05, 'weight_decay_nn': 2.5312343742438776e-07, 'dropout_rate': 0.25} CV_score=0.0042\n",
      "[Calib 15/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.009562346520989787, 'momentum': 0.96527526136161, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 6.0012286734118126e-05, 'init_scale_nn': 2.575810049134846e-05, 'weight_decay_motifs': 6.652192183238886e-11, 'weight_decay_nn': 1.7504619263820165e-06, 'dropout_rate': 0.5} CV_score=0.6045\n",
      "[Calib 16/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.00900309465508187, 'momentum': 0.9666308287264643, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.00010292066481336655, 'init_scale_nn': 0.0001205759149257543, 'weight_decay_motifs': 2.828558805212517e-05, 'weight_decay_nn': 1.8251412457448964e-09, 'dropout_rate': 0.0} CV_score=0.6529\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=-0.0038, std=0.9445, unique=[-1.649212  -1.6134442 -1.6076684 -1.6068466 -1.6039681 -1.6030033\n",
      " -1.5937419 -1.5885885 -1.5817671 -1.5776969]\n",
      " preds : mean=0.2678, std=0.0000, min=0.2678, max=0.2678\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=-0.0038, std=0.9445, unique=[-1.649212  -1.6134442 -1.6076684 -1.6068466 -1.6039681 -1.6030033\n",
      " -1.5937419 -1.5885885 -1.5817671 -1.5776969]\n",
      " preds : mean=0.0836, std=0.0000, min=0.0836, max=0.0836\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=-0.0038, std=0.9445, unique=[-1.649212  -1.6134442 -1.6076684 -1.6068466 -1.6039681 -1.6030033\n",
      " -1.5937419 -1.5885885 -1.5817671 -1.5776969]\n",
      " preds : mean=0.0895, std=0.0000, min=0.0895, max=0.0895\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=-0.0038, std=0.9445, unique=[-1.649212  -1.6134442 -1.6076684 -1.6068466 -1.6039681 -1.6030033\n",
      " -1.5937419 -1.5885885 -1.5817671 -1.5776969]\n",
      " preds : mean=0.0454, std=0.0000, min=0.0454, max=0.0454\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=-0.0038, std=0.9445, unique=[-1.649212  -1.6134442 -1.6076684 -1.6068466 -1.6039681 -1.6030033\n",
      " -1.5937419 -1.5885885 -1.5817671 -1.5776969]\n",
      " preds : mean=0.0074, std=0.0000, min=0.0074, max=0.0074\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=-0.0005, std=1.0052, unique=[-1.6391003 -1.6087955 -1.6028873 -1.5994041 -1.5992286 -1.5940433\n",
      " -1.593559  -1.5915841 -1.5902673 -1.5876826]\n",
      " preds : mean=0.0646, std=0.0000, min=0.0646, max=0.0646\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=-0.0005, std=1.0052, unique=[-1.6391003 -1.6087955 -1.6028873 -1.5994041 -1.5992286 -1.5940433\n",
      " -1.593559  -1.5915841 -1.5902673 -1.5876826]\n",
      " preds : mean=0.1029, std=0.0000, min=0.1029, max=0.1029\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=-0.0005, std=1.0052, unique=[-1.6391003 -1.6087955 -1.6028873 -1.5994041 -1.5992286 -1.5940433\n",
      " -1.593559  -1.5915841 -1.5902673 -1.5876826]\n",
      " preds : mean=-0.0220, std=0.0000, min=-0.0220, max=-0.0220\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=-0.0005, std=1.0052, unique=[-1.6391003 -1.6087955 -1.6028873 -1.5994041 -1.5992286 -1.5940433\n",
      " -1.593559  -1.5915841 -1.5902673 -1.5876826]\n",
      " preds : mean=-0.0896, std=0.0000, min=-0.0896, max=-0.0896\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=-0.0005, std=1.0052, unique=[-1.6391003 -1.6087955 -1.6028873 -1.5994041 -1.5992286 -1.5940433\n",
      " -1.593559  -1.5915841 -1.5902673 -1.5876826]\n",
      " preds : mean=-0.0084, std=0.0000, min=-0.0084, max=-0.0084\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=0.0076, std=1.0099, unique=[-1.6177288 -1.6131452 -1.6124986 -1.6081908 -1.6045547 -1.6027195\n",
      " -1.6008122 -1.5996478 -1.5947446 -1.5823246]\n",
      " preds : mean=-0.0444, std=0.0000, min=-0.0444, max=-0.0444\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=0.0076, std=1.0099, unique=[-1.6177288 -1.6131452 -1.6124986 -1.6081908 -1.6045547 -1.6027195\n",
      " -1.6008122 -1.5996478 -1.5947446 -1.5823246]\n",
      " preds : mean=0.0349, std=0.0000, min=0.0349, max=0.0349\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=0.0076, std=1.0099, unique=[-1.6177288 -1.6131452 -1.6124986 -1.6081908 -1.6045547 -1.6027195\n",
      " -1.6008122 -1.5996478 -1.5947446 -1.5823246]\n",
      " preds : mean=0.0789, std=0.0000, min=0.0789, max=0.0789\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=0.0076, std=1.0099, unique=[-1.6177288 -1.6131452 -1.6124986 -1.6081908 -1.6045547 -1.6027195\n",
      " -1.6008122 -1.5996478 -1.5947446 -1.5823246]\n",
      " preds : mean=0.0383, std=0.0000, min=0.0383, max=0.0383\n",
      "[Calib 17/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.046293145107798646, 'momentum': 0.9578786942443916, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0008747411948257162, 'init_scale_nn': 0.0012789814320761316, 'weight_decay_motifs': 2.2961437419123336e-14, 'weight_decay_nn': 6.724604091481423e-05, 'dropout_rate': 0.5} CV_score=0.4891\n",
      "[Calib 18/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.0028849294598361137, 'momentum': 0.9552096673527234, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.2450038724922712e-07, 'init_scale_nn': 0.000436965410758217, 'weight_decay_motifs': 5.354647689169606e-07, 'weight_decay_nn': 0.0008334076366965004, 'dropout_rate': 0.25} CV_score=0.7005\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=0.0069, std=0.9847, unique=[-1.6391003 -1.6177288 -1.6131452 -1.6087955 -1.6076684 -1.6068466\n",
      " -1.6027195 -1.6008122 -1.5996478 -1.5994041]\n",
      " preds : mean=0.0315, std=0.0000, min=0.0315, max=0.0315\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=0.0069, std=0.9847, unique=[-1.6391003 -1.6177288 -1.6131452 -1.6087955 -1.6076684 -1.6068466\n",
      " -1.6027195 -1.6008122 -1.5996478 -1.5994041]\n",
      " preds : mean=0.0216, std=0.0000, min=0.0216, max=0.0216\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=0.0069, std=0.9847, unique=[-1.6391003 -1.6177288 -1.6131452 -1.6087955 -1.6076684 -1.6068466\n",
      " -1.6027195 -1.6008122 -1.5996478 -1.5994041]\n",
      " preds : mean=0.0296, std=0.0000, min=0.0296, max=0.0296\n",
      "[Calib 19/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.006055369305645226, 'momentum': 0.9717026169585702, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.173299650604148e-06, 'init_scale_nn': 0.0003829022471751396, 'weight_decay_motifs': 1.983657362980013e-15, 'weight_decay_nn': 1.1445131968647707e-06, 'dropout_rate': 0.25} CV_score=0.6449\n",
      "[Calib 20/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.03214877471880277, 'momentum': 0.9626014702026136, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 2.00218394076895e-05, 'init_scale_nn': 0.00034132526992466434, 'weight_decay_motifs': 1.6508094638728815e-13, 'weight_decay_nn': 6.364994862034022e-09, 'dropout_rate': 0.0} CV_score=0.5016\n",
      "[Calib 21/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.0010083432437166335, 'momentum': 0.9625908947468228, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 2.352066408882256e-06, 'init_scale_nn': 5.780372985972926e-05, 'weight_decay_motifs': 2.257547818513943e-05, 'weight_decay_nn': 3.28009859997357e-09, 'dropout_rate': 0.0} CV_score=0.6437\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=-0.0018, std=0.9768, unique=[-1.6391003 -1.6045547 -1.6008122 -1.5994041 -1.5937419 -1.5902673\n",
      " -1.5826494 -1.5805047 -1.577265  -1.5771685]\n",
      " preds : mean=0.0097, std=0.0000, min=0.0097, max=0.0097\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=-0.0018, std=0.9768, unique=[-1.6391003 -1.6045547 -1.6008122 -1.5994041 -1.5937419 -1.5902673\n",
      " -1.5826494 -1.5805047 -1.577265  -1.5771685]\n",
      " preds : mean=-0.0396, std=0.0000, min=-0.0396, max=-0.0396\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=-0.0018, std=0.9768, unique=[-1.6391003 -1.6045547 -1.6008122 -1.5994041 -1.5937419 -1.5902673\n",
      " -1.5826494 -1.5805047 -1.577265  -1.5771685]\n",
      " preds : mean=-0.0252, std=0.0000, min=-0.0252, max=-0.0252\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=-0.0018, std=0.9768, unique=[-1.6391003 -1.6045547 -1.6008122 -1.5994041 -1.5937419 -1.5902673\n",
      " -1.5826494 -1.5805047 -1.577265  -1.5771685]\n",
      " preds : mean=0.0828, std=0.0000, min=0.0828, max=0.0828\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=0.0082, std=0.9624, unique=[-1.6177288 -1.6134442 -1.6131452 -1.6087955 -1.6081908 -1.6068466\n",
      " -1.6028873 -1.5996478 -1.5992286 -1.5940433]\n",
      " preds : mean=-0.0248, std=0.0000, min=-0.0248, max=-0.0248\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=0.0082, std=0.9624, unique=[-1.6177288 -1.6134442 -1.6131452 -1.6087955 -1.6081908 -1.6068466\n",
      " -1.6028873 -1.5996478 -1.5992286 -1.5940433]\n",
      " preds : mean=-0.0854, std=0.0000, min=-0.0854, max=-0.0854\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=0.0082, std=0.9624, unique=[-1.6177288 -1.6134442 -1.6131452 -1.6087955 -1.6081908 -1.6068466\n",
      " -1.6028873 -1.5996478 -1.5992286 -1.5940433]\n",
      " preds : mean=-0.0960, std=0.0000, min=-0.0960, max=-0.0960\n",
      "[Calib 22/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.009149989463815313, 'momentum': 0.9800240299036524, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 3.669243702638278e-07, 'init_scale_nn': 8.279952098705697e-05, 'weight_decay_motifs': 1.7451399956005105e-14, 'weight_decay_nn': 8.480129348208204e-09, 'dropout_rate': 0.0} CV_score=0.3799\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0046, std=1.0265, unique=[-1.6039681 -1.6030033 -1.6028873 -1.5992286 -1.5817671 -1.5744097\n",
      " -1.5731183 -1.5667374 -1.5606112 -1.5591961]\n",
      " preds : mean=-0.0101, std=0.0000, min=-0.0101, max=-0.0101\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0046, std=1.0265, unique=[-1.6039681 -1.6030033 -1.6028873 -1.5992286 -1.5817671 -1.5744097\n",
      " -1.5731183 -1.5667374 -1.5606112 -1.5591961]\n",
      " preds : mean=0.0869, std=0.0000, min=0.0869, max=0.0869\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0046, std=1.0265, unique=[-1.6039681 -1.6030033 -1.6028873 -1.5992286 -1.5817671 -1.5744097\n",
      " -1.5731183 -1.5667374 -1.5606112 -1.5591961]\n",
      " preds : mean=0.0164, std=0.0000, min=0.0164, max=0.0164\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0046, std=1.0265, unique=[-1.6039681 -1.6030033 -1.6028873 -1.5992286 -1.5817671 -1.5744097\n",
      " -1.5731183 -1.5667374 -1.5606112 -1.5591961]\n",
      " preds : mean=-0.0283, std=0.0000, min=-0.0283, max=-0.0283\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=-0.0020, std=0.9703, unique=[-1.649212  -1.6391003 -1.6087955 -1.6027195 -1.6008122 -1.5996478\n",
      " -1.5947446 -1.5940433 -1.5937419 -1.593559 ]\n",
      " preds : mean=-0.0216, std=0.0000, min=-0.0216, max=-0.0216\n",
      "[DEBUG] Fold 1 got NaN score\n",
      " labels: mean=-0.0020, std=0.9703, unique=[-1.649212  -1.6391003 -1.6087955 -1.6027195 -1.6008122 -1.5996478\n",
      " -1.5947446 -1.5940433 -1.5937419 -1.593559 ]\n",
      " preds : mean=-0.0806, std=0.0000, min=-0.0806, max=-0.0806\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=0.0008, std=0.9630, unique=[-1.6177288 -1.6134442 -1.6131452 -1.6124986 -1.6081908 -1.6076684\n",
      " -1.6068466 -1.6045547 -1.5994041 -1.5915841]\n",
      " preds : mean=-0.0208, std=0.0000, min=-0.0208, max=-0.0208\n",
      "[Calib 23/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.04974775683535305, 'momentum': 0.9505027885158852, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.000475675721733678, 'init_scale_nn': 0.008825403796424509, 'weight_decay_motifs': 4.937812370613732e-10, 'weight_decay_nn': 3.310335402846365e-09, 'dropout_rate': 0.5} CV_score=0.3145\n",
      "[Calib 24/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.0015807657466936336, 'momentum': 0.9812968196143282, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 3.916118131001087e-05, 'init_scale_nn': 0.0006589682857745585, 'weight_decay_motifs': 2.3068332159794556e-05, 'weight_decay_nn': 3.91511784638585e-06, 'dropout_rate': 0.0} CV_score=0.6605\n",
      "[Calib 25/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.0005418823148908947, 'momentum': 0.9724649689328816, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0004276899937380173, 'init_scale_nn': 0.006632887021054554, 'weight_decay_motifs': 2.0962503347868072e-15, 'weight_decay_nn': 2.050347984452804e-06, 'dropout_rate': 0.5} CV_score=0.6722\n",
      "[Calib 26/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.0036414457109431066, 'momentum': 0.9646758713076828, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 2.1975895336658958e-06, 'init_scale_nn': 0.000107250241814267, 'weight_decay_motifs': 4.943709718685948e-15, 'weight_decay_nn': 2.8481027093545875e-10, 'dropout_rate': 0.0} CV_score=0.6639\n",
      "[Calib 27/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.01673260430484613, 'momentum': 0.9654710604640364, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.00013284474225481205, 'init_scale_nn': 3.539706901154683e-05, 'weight_decay_motifs': 1.2759578490607102e-08, 'weight_decay_nn': 1.132895374336949e-06, 'dropout_rate': 0.5} CV_score=0.3846\n",
      "[Calib 28/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.0007797867580954044, 'momentum': 0.9695473031588533, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.6748299378751442e-06, 'init_scale_nn': 1.1486809451450634e-05, 'weight_decay_motifs': 1.9932835708907017e-11, 'weight_decay_nn': 0.0001299523452314416, 'dropout_rate': 0.5} CV_score=0.6998\n",
      "[Calib 29/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.014485909921510514, 'momentum': 0.9747976741236665, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 9.203743516766276e-06, 'init_scale_nn': 0.0026345279139112694, 'weight_decay_motifs': 2.377061378167445e-09, 'weight_decay_nn': 1.1665908652589263e-10, 'dropout_rate': 0.0} CV_score=0.5529\n",
      "[Calib 30/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.0024834412782361757, 'momentum': 0.9793456645377906, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 3.1561681100198e-05, 'init_scale_nn': 0.00112809709707674, 'weight_decay_motifs': 1.5849147811119215e-12, 'weight_decay_nn': 6.903546380376308e-10, 'dropout_rate': 0.25} CV_score=0.6802\n",
      "Best hyperparams: {'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.0028849294598361137, 'momentum': 0.9552096673527234, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.2450038724922712e-07, 'init_scale_nn': 0.000436965410758217, 'weight_decay_motifs': 5.354647689169606e-07, 'weight_decay_nn': 0.0008334076366965004, 'dropout_rate': 0.25} with CV score 0.7005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syl/anaconda3/envs/tfbs/lib/python3.9/site-packages/torch/nn/modules/loss.py:616: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/syl/anaconda3/envs/tfbs/lib/python3.9/site-packages/torch/nn/modules/loss.py:616: UserWarning: Using a target size (torch.Size([26, 1])) that is different to the input size (torch.Size([26])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch01 loss=0.9774\n",
      "[Train] Epoch02 loss=0.9749\n",
      "[Train] Epoch03 loss=0.9748\n",
      "[Train] Epoch04 loss=0.9750\n",
      "[Train] Epoch05 loss=0.9749\n",
      "[Train] Epoch06 loss=0.9748\n",
      "[Train] Epoch07 loss=0.9750\n",
      "[Train] Epoch08 loss=0.9748\n",
      "[Train] Epoch09 loss=0.9750\n",
      "[Train] Epoch10 loss=0.9749\n",
      "[Train] Epoch11 loss=0.9750\n",
      "[Train] Epoch12 loss=0.9750\n",
      "[Train] Epoch13 loss=0.9752\n",
      "[Train] Epoch14 loss=0.9748\n",
      "[Train] Epoch15 loss=0.9747\n",
      "[Train] Epoch16 loss=0.9754\n",
      "[Train] Epoch17 loss=0.9752\n",
      "[Train] Epoch18 loss=0.9749\n",
      "[Train] Epoch19 loss=0.9751\n",
      "[Train] Epoch20 loss=0.9753\n",
      ">> Test Pearson: 0.0826\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python train.py \\\n",
    "  --data_type PBM \\\n",
    "  --seq_file ../DeepBind/data/dream5/pbm/sequences.tsv.gz \\\n",
    "  --tgt_file ../DeepBind/data/dream5/pbm/targets.tsv.gz \\\n",
    "  --tf_col TF_1 \\\n",
    "  --max_len 36 \\\n",
    "  --epochs 20 \\\n",
    "  --device cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afe725d5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Calib 01/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.0011480914295024973, 'momentum': 0.9821899920516143, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0008640157554929006, 'init_scale_nn': 5.867932210863854e-05, 'weight_decay_motifs': 8.590037832094837e-10, 'weight_decay_nn': 2.3268530601033645e-05, 'dropout_rate': 0.0} CV_score=0.7672\n",
      "[Calib 02/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.035106231070142456, 'momentum': 0.9892113028210163, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 5.839050380954199e-06, 'init_scale_nn': 0.0031699176125715273, 'weight_decay_motifs': 3.3458339071104138e-12, 'weight_decay_nn': 0.0002891076155385852, 'dropout_rate': 0.25} CV_score=0.4417\n",
      "[Calib 03/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.02211650232615001, 'momentum': 0.9893317427003273, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.3451143730215717e-07, 'init_scale_nn': 0.0008916132877194975, 'weight_decay_motifs': 1.2979369797261766e-14, 'weight_decay_nn': 2.6710336485116668e-06, 'dropout_rate': 0.0} CV_score=0.6733\n",
      "[Calib 04/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.000945390299207717, 'momentum': 0.9711339464240599, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 6.456890172296909e-05, 'init_scale_nn': 0.0015768773162692952, 'weight_decay_motifs': 3.403148738670718e-08, 'weight_decay_nn': 1.0780159129346052e-10, 'dropout_rate': 0.5} CV_score=0.7281\n",
      "[Calib 05/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.008952715234283181, 'momentum': 0.9739555047922661, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 4.1662923789687375e-06, 'init_scale_nn': 8.9756665410399e-05, 'weight_decay_motifs': 1.6581306221585508e-06, 'weight_decay_nn': 1.0397680954175552e-05, 'dropout_rate': 0.25} CV_score=0.7630\n",
      "[Calib 06/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.01656502943692291, 'momentum': 0.9598405978039166, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0001363143060404419, 'init_scale_nn': 0.0025941944434483464, 'weight_decay_motifs': 0.00015127047118272623, 'weight_decay_nn': 0.0004551997646285115, 'dropout_rate': 0.25} CV_score=0.7378\n",
      "[Calib 07/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.0022594358345429237, 'momentum': 0.9844082100648985, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.5571795651743746e-07, 'init_scale_nn': 0.003236628683733967, 'weight_decay_motifs': 1.877757431893778e-12, 'weight_decay_nn': 5.24103912606846e-07, 'dropout_rate': 0.25} CV_score=0.7811\n",
      "[Calib 08/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.0008702499081142241, 'momentum': 0.9814750481255003, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 8.266256119509143e-05, 'init_scale_nn': 0.003914878363312276, 'weight_decay_motifs': 1.2826378918424466e-06, 'weight_decay_nn': 4.886862774402339e-05, 'dropout_rate': 0.5} CV_score=0.7506\n",
      "[Calib 09/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.00771566443390225, 'momentum': 0.9580574699269684, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 3.497992955989842e-05, 'init_scale_nn': 0.004155571200459924, 'weight_decay_motifs': 0.0006014658295964311, 'weight_decay_nn': 4.3602816847768777e-07, 'dropout_rate': 0.0} CV_score=0.7194\n",
      "[Calib 10/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.004921413793240411, 'momentum': 0.9666799483684705, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 2.9934607154648107e-07, 'init_scale_nn': 3.19427300887096e-05, 'weight_decay_motifs': 1.8311273052085396e-15, 'weight_decay_nn': 9.952035550996072e-08, 'dropout_rate': 0.25} CV_score=0.7670\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0001, std=1.0033, unique=[-0.84421784 -0.84011173 -0.8354929  -0.83400214 -0.8339285  -0.83373666\n",
      " -0.8334785  -0.83342427 -0.8332666  -0.8322697 ]\n",
      " preds : mean=-0.0070, std=0.0000, min=-0.0070, max=-0.0070\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0001, std=1.0033, unique=[-0.84421784 -0.84011173 -0.8354929  -0.83400214 -0.8339285  -0.83373666\n",
      " -0.8334785  -0.83342427 -0.8332666  -0.8322697 ]\n",
      " preds : mean=0.0072, std=0.0000, min=0.0072, max=0.0072\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0001, std=1.0033, unique=[-0.84421784 -0.84011173 -0.8354929  -0.83400214 -0.8339285  -0.83373666\n",
      " -0.8334785  -0.83342427 -0.8332666  -0.8322697 ]\n",
      " preds : mean=0.0017, std=0.0000, min=0.0017, max=0.0017\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0001, std=1.0033, unique=[-0.84421784 -0.84011173 -0.8354929  -0.83400214 -0.8339285  -0.83373666\n",
      " -0.8334785  -0.83342427 -0.8332666  -0.8322697 ]\n",
      " preds : mean=-0.0620, std=0.0000, min=-0.0620, max=-0.0620\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0001, std=1.0033, unique=[-0.84421784 -0.84011173 -0.8354929  -0.83400214 -0.8339285  -0.83373666\n",
      " -0.8334785  -0.83342427 -0.8332666  -0.8322697 ]\n",
      " preds : mean=-0.0013, std=0.0000, min=-0.0013, max=-0.0013\n",
      "[Calib 11/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.038658582708940584, 'momentum': 0.9779790055213172, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.162653705599189e-07, 'init_scale_nn': 8.341802642009752e-05, 'weight_decay_motifs': 2.8385283405117e-15, 'weight_decay_nn': 2.177272373517844e-09, 'dropout_rate': 0.5} CV_score=0.4644\n",
      "[Calib 12/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.007854707875597566, 'momentum': 0.9775737443737098, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 5.744664308771133e-07, 'init_scale_nn': 0.0002490332590978697, 'weight_decay_motifs': 2.204974886196426e-12, 'weight_decay_nn': 1.3504502347114553e-06, 'dropout_rate': 0.0} CV_score=0.7618\n",
      "[Calib 13/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.0012938363520771914, 'momentum': 0.9702168302872594, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 6.156392370977768e-07, 'init_scale_nn': 0.0006528447341703557, 'weight_decay_motifs': 2.796204347609994e-07, 'weight_decay_nn': 5.156737024972545e-05, 'dropout_rate': 0.25} CV_score=0.7733\n",
      "[Calib 14/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.006357881504577348, 'momentum': 0.9846982111741183, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 3.2668136224967826e-06, 'init_scale_nn': 3.5640382874205665e-05, 'weight_decay_motifs': 0.00011114872641563888, 'weight_decay_nn': 6.458603418032037e-07, 'dropout_rate': 0.0} CV_score=0.7663\n",
      "[Calib 15/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.0005012618862852739, 'momentum': 0.9837010730591388, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.381904012045366e-06, 'init_scale_nn': 0.005517588459007622, 'weight_decay_motifs': 3.487653804866883e-14, 'weight_decay_nn': 1.5249373664811292e-09, 'dropout_rate': 0.0} CV_score=0.6910\n",
      "[Calib 16/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.0007600929122354442, 'momentum': 0.9754662666573074, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 2.700468431215881e-06, 'init_scale_nn': 0.0006294431171349719, 'weight_decay_motifs': 1.9180405355665515e-10, 'weight_decay_nn': 4.499773794857206e-06, 'dropout_rate': 0.25} CV_score=0.7487\n",
      "[Calib 17/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.025587381339313188, 'momentum': 0.9554550348841967, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 2.9425385408577647e-07, 'init_scale_nn': 0.00040494727602274926, 'weight_decay_motifs': 6.7481495380101025e-12, 'weight_decay_nn': 3.166247769249328e-09, 'dropout_rate': 0.25} CV_score=0.5834\n",
      "[Calib 18/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.005341462785801371, 'momentum': 0.9659172574823323, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.092647092391406e-06, 'init_scale_nn': 0.0027511582626342512, 'weight_decay_motifs': 1.485010194577679e-07, 'weight_decay_nn': 0.0006003102422746271, 'dropout_rate': 0.0} CV_score=0.7679\n",
      "[Calib 19/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.0019570803506997574, 'momentum': 0.9844951667531605, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.3052127643480263e-07, 'init_scale_nn': 0.009352476857859587, 'weight_decay_motifs': 7.419558016219269e-12, 'weight_decay_nn': 1.7330660673278922e-06, 'dropout_rate': 0.0} CV_score=0.7647\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0002, std=0.9702, unique=[-0.8506559  -0.84628516 -0.844383   -0.84421784 -0.84011173 -0.8370436\n",
      " -0.83681315 -0.83659    -0.8358889  -0.83480114]\n",
      " preds : mean=-0.0002, std=0.0000, min=-0.0002, max=-0.0002\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0002, std=0.9702, unique=[-0.8506559  -0.84628516 -0.844383   -0.84421784 -0.84011173 -0.8370436\n",
      " -0.83681315 -0.83659    -0.8358889  -0.83480114]\n",
      " preds : mean=0.0280, std=0.0000, min=0.0280, max=0.0280\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0002, std=0.9702, unique=[-0.8506559  -0.84628516 -0.844383   -0.84421784 -0.84011173 -0.8370436\n",
      " -0.83681315 -0.83659    -0.8358889  -0.83480114]\n",
      " preds : mean=0.0746, std=0.0000, min=0.0746, max=0.0746\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0002, std=0.9702, unique=[-0.8506559  -0.84628516 -0.844383   -0.84421784 -0.84011173 -0.8370436\n",
      " -0.83681315 -0.83659    -0.8358889  -0.83480114]\n",
      " preds : mean=0.1376, std=0.0000, min=0.1376, max=0.1376\n",
      "[DEBUG] Fold 0 got NaN score\n",
      " labels: mean=0.0002, std=0.9702, unique=[-0.8506559  -0.84628516 -0.844383   -0.84421784 -0.84011173 -0.8370436\n",
      " -0.83681315 -0.83659    -0.8358889  -0.83480114]\n",
      " preds : mean=-0.0128, std=0.0000, min=-0.0128, max=-0.0128\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=-0.0025, std=0.9896, unique=[-0.85196656 -0.8414942  -0.8409581  -0.8379093  -0.8354929  -0.83400214\n",
      " -0.83381206 -0.83373666 -0.83342427 -0.83296055]\n",
      " preds : mean=-0.0300, std=0.0000, min=-0.0300, max=-0.0300\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=-0.0025, std=0.9896, unique=[-0.85196656 -0.8414942  -0.8409581  -0.8379093  -0.8354929  -0.83400214\n",
      " -0.83381206 -0.83373666 -0.83342427 -0.83296055]\n",
      " preds : mean=0.0169, std=0.0000, min=0.0169, max=0.0169\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=-0.0025, std=0.9896, unique=[-0.85196656 -0.8414942  -0.8409581  -0.8379093  -0.8354929  -0.83400214\n",
      " -0.83381206 -0.83373666 -0.83342427 -0.83296055]\n",
      " preds : mean=-0.0266, std=0.0000, min=-0.0266, max=-0.0266\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=-0.0025, std=0.9896, unique=[-0.85196656 -0.8414942  -0.8409581  -0.8379093  -0.8354929  -0.83400214\n",
      " -0.83381206 -0.83373666 -0.83342427 -0.83296055]\n",
      " preds : mean=0.0199, std=0.0000, min=0.0199, max=0.0199\n",
      "[DEBUG] Fold 2 got NaN score\n",
      " labels: mean=-0.0025, std=0.9896, unique=[-0.85196656 -0.8414942  -0.8409581  -0.8379093  -0.8354929  -0.83400214\n",
      " -0.83381206 -0.83373666 -0.83342427 -0.83296055]\n",
      " preds : mean=-0.0067, std=0.0000, min=-0.0067, max=-0.0067\n",
      "[Calib 20/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.049500615442927845, 'momentum': 0.9868170673776891, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0004674099947116768, 'init_scale_nn': 0.0005958534165478246, 'weight_decay_motifs': 2.2855075781145134e-13, 'weight_decay_nn': 5.312425518014887e-06, 'dropout_rate': 0.0} CV_score=0.6117\n",
      "[Calib 21/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.019391865110277087, 'momentum': 0.9841657479941296, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.7823079903832403e-05, 'init_scale_nn': 1.749410451442542e-05, 'weight_decay_motifs': 2.8218540676037432e-09, 'weight_decay_nn': 7.195640461993477e-05, 'dropout_rate': 0.5} CV_score=0.6118\n",
      "[Calib 22/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.009726497016081628, 'momentum': 0.9524568243950305, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 1.494332990505509e-06, 'init_scale_nn': 1.143584498293374e-05, 'weight_decay_motifs': 4.445785360971937e-15, 'weight_decay_nn': 5.9515750473850126e-05, 'dropout_rate': 0.0} CV_score=0.7323\n",
      "[Calib 23/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.001190460102880269, 'momentum': 0.9508889461742508, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 3.874944121617503e-05, 'init_scale_nn': 0.006916660116913885, 'weight_decay_motifs': 1.1969796253350283e-14, 'weight_decay_nn': 2.1521084390324e-06, 'dropout_rate': 0.5} CV_score=0.7454\n",
      "[Calib 24/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.020898292498944482, 'momentum': 0.9603745792278888, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0002942758721201329, 'init_scale_nn': 6.435973476776883e-05, 'weight_decay_motifs': 3.8519710359619685e-07, 'weight_decay_nn': 9.108779253746614e-09, 'dropout_rate': 0.25} CV_score=0.6328\n",
      "[Calib 25/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.001846743004355402, 'momentum': 0.9590115786209622, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0002906779230078627, 'init_scale_nn': 0.00641945356776258, 'weight_decay_motifs': 0.0005036363928861913, 'weight_decay_nn': 0.0007300748753003009, 'dropout_rate': 0.5} CV_score=0.7606\n",
      "[Calib 26/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.013523636704228313, 'momentum': 0.9704478233268107, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0001400522162053987, 'init_scale_nn': 0.008345430535577191, 'weight_decay_motifs': 1.781718812272637e-12, 'weight_decay_nn': 1.3013725347525239e-07, 'dropout_rate': 0.25} CV_score=0.6933\n",
      "[Calib 27/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.0012040492102181936, 'momentum': 0.9587421815702423, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 3.7184740713970596e-07, 'init_scale_nn': 5.472998761695505e-05, 'weight_decay_motifs': 3.8286489014108537e-05, 'weight_decay_nn': 4.687385855905097e-09, 'dropout_rate': 0.0} CV_score=0.6934\n",
      "[Calib 28/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.001095541153846103, 'momentum': 0.9755491231444188, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 8.595145846852055e-07, 'init_scale_nn': 0.0018569221382866417, 'weight_decay_motifs': 2.978021182679687e-09, 'weight_decay_nn': 1.4497592699309329e-06, 'dropout_rate': 0.25} CV_score=0.7480\n",
      "[Calib 29/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 0, 'lr': 0.003148589570489258, 'momentum': 0.9606418497391834, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 2.02047062368722e-05, 'init_scale_nn': 3.1968331974880165e-05, 'weight_decay_motifs': 0.000120197954665869, 'weight_decay_nn': 2.7576893447105975e-10, 'dropout_rate': 0.25} CV_score=0.7823\n",
      "[Calib 30/30] hp={'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.0070665605179896, 'momentum': 0.9823419268451906, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0003102064974920151, 'init_scale_nn': 0.001200933503136704, 'weight_decay_motifs': 1.0136053053974128e-10, 'weight_decay_nn': 3.305989876540466e-10, 'dropout_rate': 0.5} CV_score=0.7900\n",
      "Best hyperparams: {'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32, 'lr': 0.0070665605179896, 'momentum': 0.9823419268451906, 'batch_size': 64, 'checkpoint_steps': [4000, 8000, 12000, 16000, 20000], 'init_scale_motifs': 0.0003102064974920151, 'init_scale_nn': 0.001200933503136704, 'weight_decay_motifs': 1.0136053053974128e-10, 'weight_decay_nn': 3.305989876540466e-10, 'dropout_rate': 0.5} with CV score 0.7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syl/anaconda3/envs/tfbs/lib/python3.9/site-packages/torch/nn/modules/loss.py:616: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch01 loss=0.9916\n",
      "[Train] Epoch02 loss=0.9914\n",
      "[Train] Epoch03 loss=0.9913\n",
      "[Train] Epoch04 loss=0.9915\n",
      "[Train] Epoch05 loss=0.9916\n",
      "[Train] Epoch06 loss=0.9914\n",
      "[Train] Epoch07 loss=0.9915\n",
      "[Train] Epoch08 loss=0.9915\n",
      "[Train] Epoch09 loss=0.9915\n",
      "[Train] Epoch10 loss=0.9914\n",
      "[Train] Epoch11 loss=0.9916\n",
      "[Train] Epoch12 loss=0.9914\n",
      "[Train] Epoch13 loss=0.9913\n",
      "[Train] Epoch14 loss=0.9915\n",
      "[Train] Epoch15 loss=0.9912\n",
      "[Train] Epoch16 loss=0.9915\n",
      "[Train] Epoch17 loss=0.9915\n",
      "[Train] Epoch18 loss=0.9915\n",
      "[Train] Epoch19 loss=0.9914\n",
      "[Train] Epoch20 loss=0.9913\n",
      ">> Test Pearson: nan (constant preds or labels; pearson undefined)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python train.py \\\n",
    "  --data_type PBM \\\n",
    "  --seq_file ../DeepBind/data/dream5/pbm/sequences.tsv.gz \\\n",
    "  --tgt_file ../DeepBind/data/dream5/pbm/targets.tsv.gz \\\n",
    "  --tf_col TF_2 \\\n",
    "  --max_len 36 \\\n",
    "  --epochs 20 \\\n",
    "  --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3322464",
   "metadata": {},
   "source": [
    "不知为何，模型一直输出常数，Pearson系数非常低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f205ea8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Calib 01/30] hp={'lr': 0.00014835053740083198, 'weight_decay': 1.7413845639000577e-05, 'batch_size': 128, 'num_kernels': 8, 'kernel_size': 36, 'fc_hidden': 64} CV_score=0.3556\n",
      "[Calib 02/30] hp={'lr': 0.0012096264455458406, 'weight_decay': 0.0008403821697095179, 'batch_size': 64, 'num_kernels': 32, 'kernel_size': 36, 'fc_hidden': 16} CV_score=0.3821\n",
      "[Calib 03/30] hp={'lr': 0.0062721644073863375, 'weight_decay': 2.7217277511657373e-06, 'batch_size': 32, 'num_kernels': 32, 'kernel_size': 12, 'fc_hidden': 64} CV_score=0.8608\n",
      "[Calib 04/30] hp={'lr': 0.00013274653952020547, 'weight_decay': 9.464889848951976e-05, 'batch_size': 32, 'num_kernels': 8, 'kernel_size': 12, 'fc_hidden': 16} CV_score=0.3716\n",
      "[Calib 05/30] hp={'lr': 0.0053032369330071535, 'weight_decay': 0.00010816246773556173, 'batch_size': 64, 'num_kernels': 8, 'kernel_size': 12, 'fc_hidden': 16} CV_score=0.8052\n",
      "[Calib 06/30] hp={'lr': 0.00015632841683064954, 'weight_decay': 0.0004314290406749512, 'batch_size': 64, 'num_kernels': 8, 'kernel_size': 24, 'fc_hidden': 32} CV_score=0.3604\n",
      "[Calib 07/30] hp={'lr': 0.0024887342431951847, 'weight_decay': 6.437130986284042e-06, 'batch_size': 128, 'num_kernels': 8, 'kernel_size': 24, 'fc_hidden': 64} CV_score=0.6602\n",
      "[Calib 08/30] hp={'lr': 0.0014063578262807589, 'weight_decay': 3.0968828026668966e-06, 'batch_size': 128, 'num_kernels': 8, 'kernel_size': 24, 'fc_hidden': 64} CV_score=0.4856\n",
      "[Calib 09/30] hp={'lr': 0.0001520029405388992, 'weight_decay': 9.628504019964902e-05, 'batch_size': 128, 'num_kernels': 32, 'kernel_size': 12, 'fc_hidden': 16} CV_score=0.4119\n",
      "[Calib 10/30] hp={'lr': 0.00020437868535546255, 'weight_decay': 7.50059392206569e-05, 'batch_size': 64, 'num_kernels': 8, 'kernel_size': 36, 'fc_hidden': 32} CV_score=0.3683\n",
      "[Calib 11/30] hp={'lr': 0.0007287266593585868, 'weight_decay': 0.0006789668002345468, 'batch_size': 32, 'num_kernels': 32, 'kernel_size': 36, 'fc_hidden': 32} CV_score=0.3829\n",
      "[Calib 12/30] hp={'lr': 0.0005472593824239502, 'weight_decay': 2.1753760444851586e-05, 'batch_size': 128, 'num_kernels': 16, 'kernel_size': 12, 'fc_hidden': 64} CV_score=0.6926\n",
      "[Calib 13/30] hp={'lr': 0.00012257419476842296, 'weight_decay': 0.00012353645186907213, 'batch_size': 64, 'num_kernels': 32, 'kernel_size': 36, 'fc_hidden': 16} CV_score=0.3684\n",
      "[Calib 14/30] hp={'lr': 0.0010994022582029388, 'weight_decay': 9.949295307218273e-05, 'batch_size': 64, 'num_kernels': 32, 'kernel_size': 24, 'fc_hidden': 64} CV_score=0.7608\n",
      "[Calib 15/30] hp={'lr': 0.00016988501913100612, 'weight_decay': 1.6268862904951414e-06, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 12, 'fc_hidden': 64} CV_score=0.4401\n",
      "[Calib 16/30] hp={'lr': 0.0002279246630047711, 'weight_decay': 0.0006846384585803196, 'batch_size': 128, 'num_kernels': 16, 'kernel_size': 12, 'fc_hidden': 64} CV_score=0.4170\n",
      "[Calib 17/30] hp={'lr': 0.00016337116794088702, 'weight_decay': 4.716001339067816e-06, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 12, 'fc_hidden': 64} CV_score=0.5564\n",
      "[Calib 18/30] hp={'lr': 0.0006376410282371874, 'weight_decay': 1.7952261977664007e-06, 'batch_size': 32, 'num_kernels': 16, 'kernel_size': 36, 'fc_hidden': 16} CV_score=0.3735\n",
      "[Calib 19/30] hp={'lr': 0.00787084689251867, 'weight_decay': 8.498397279325406e-06, 'batch_size': 64, 'num_kernels': 32, 'kernel_size': 36, 'fc_hidden': 32} CV_score=0.3672\n",
      "[Calib 20/30] hp={'lr': 0.0007763289002873985, 'weight_decay': 1.5335179680366893e-05, 'batch_size': 32, 'num_kernels': 16, 'kernel_size': 36, 'fc_hidden': 32} CV_score=0.3745\n",
      "[Calib 21/30] hp={'lr': 0.008789736542555106, 'weight_decay': 1.9274798557485053e-06, 'batch_size': 128, 'num_kernels': 8, 'kernel_size': 12, 'fc_hidden': 32} CV_score=0.7900\n",
      "[Calib 22/30] hp={'lr': 0.00028083631349584915, 'weight_decay': 1.0337954889252785e-05, 'batch_size': 128, 'num_kernels': 32, 'kernel_size': 36, 'fc_hidden': 16} CV_score=0.3723\n",
      "[Calib 23/30] hp={'lr': 0.0004570215440643067, 'weight_decay': 1.4056003083969878e-06, 'batch_size': 32, 'num_kernels': 8, 'kernel_size': 24, 'fc_hidden': 64} CV_score=0.5372\n",
      "[Calib 24/30] hp={'lr': 0.00026716079986039966, 'weight_decay': 3.624548608854033e-06, 'batch_size': 64, 'num_kernels': 8, 'kernel_size': 36, 'fc_hidden': 16} CV_score=0.3666\n",
      "[Calib 25/30] hp={'lr': 0.005087146795560643, 'weight_decay': 3.458903380061979e-05, 'batch_size': 128, 'num_kernels': 8, 'kernel_size': 24, 'fc_hidden': 32} CV_score=0.6166\n",
      "[Calib 26/30] hp={'lr': 0.0002871123645434232, 'weight_decay': 1.7318091484552828e-06, 'batch_size': 128, 'num_kernels': 8, 'kernel_size': 24, 'fc_hidden': 64} CV_score=0.3731\n",
      "[Calib 27/30] hp={'lr': 0.004346794589659875, 'weight_decay': 7.926036249325756e-06, 'batch_size': 32, 'num_kernels': 8, 'kernel_size': 36, 'fc_hidden': 64} CV_score=0.3664\n",
      "[Calib 28/30] hp={'lr': 0.00156480715441693, 'weight_decay': 8.247637075152752e-05, 'batch_size': 32, 'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32} CV_score=0.7484\n",
      "[Calib 29/30] hp={'lr': 0.004699444673319281, 'weight_decay': 8.263458903949246e-06, 'batch_size': 32, 'num_kernels': 8, 'kernel_size': 36, 'fc_hidden': 32} CV_score=0.3664\n",
      "[Calib 30/30] hp={'lr': 0.0010040560366600542, 'weight_decay': 6.722192718007134e-06, 'batch_size': 64, 'num_kernels': 8, 'kernel_size': 12, 'fc_hidden': 16} CV_score=0.6983\n",
      "Best hyperparams: {'lr': 0.0062721644073863375, 'weight_decay': 2.7217277511657373e-06, 'batch_size': 32, 'num_kernels': 32, 'kernel_size': 12, 'fc_hidden': 64} with CV score 0.8608\n",
      "[Train] Epoch01 loss=0.3982\n",
      "[Train] Epoch02 loss=0.2666\n",
      "[Train] Epoch03 loss=0.2501\n",
      "[Train] Epoch04 loss=0.2418\n",
      "[Train] Epoch05 loss=0.2363\n",
      "[Train] Epoch06 loss=0.2334\n",
      "[Train] Epoch07 loss=0.2289\n",
      "[Train] Epoch08 loss=0.2273\n",
      "[Train] Epoch09 loss=0.2251\n",
      "[Train] Epoch10 loss=0.2228\n",
      "[Train] Epoch11 loss=0.2221\n",
      "[Train] Epoch12 loss=0.2205\n",
      "[Train] Epoch13 loss=0.2193\n",
      "[Train] Epoch14 loss=0.2195\n",
      "[Train] Epoch15 loss=0.2174\n",
      "[Train] Epoch16 loss=0.2168\n",
      "[Train] Epoch17 loss=0.2159\n",
      "[Train] Epoch18 loss=0.2153\n",
      "[Train] Epoch19 loss=0.2145\n",
      "[Train] Epoch20 loss=0.2152\n",
      ">> Test Pearson: 0.8830\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python train.py \\\n",
    "  --data_type PBM \\\n",
    "  --seq_file ../DeepBind/data/dream5/pbm/sequences.tsv.gz \\\n",
    "  --tgt_file ../DeepBind/data/dream5/pbm/targets.tsv.gz \\\n",
    "  --tf_col TF_3 \\\n",
    "  --max_len 36 \\\n",
    "  --epochs 20 \\\n",
    "  --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ef802",
   "metadata": {},
   "source": [
    "再试一下TF_1 & TF_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a05e6a2c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Calib 01/30] hp={'lr': 0.0010618096556056875, 'weight_decay': 0.00035152882381754515, 'batch_size': 32, 'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32} CV_score=0.5597\n",
      "[Calib 02/30] hp={'lr': 0.00043968942294645276, 'weight_decay': 3.728148514167497e-06, 'batch_size': 128, 'num_kernels': 16, 'kernel_size': 12, 'fc_hidden': 64} CV_score=0.3929\n",
      "[Calib 03/30] hp={'lr': 0.0015884997200713304, 'weight_decay': 0.00012847898922006124, 'batch_size': 32, 'num_kernels': 32, 'kernel_size': 24, 'fc_hidden': 64} CV_score=0.6449\n",
      "[Calib 04/30] hp={'lr': 0.0044260304662261055, 'weight_decay': 0.00019402007410656294, 'batch_size': 64, 'num_kernels': 8, 'kernel_size': 12, 'fc_hidden': 16} CV_score=0.6306\n",
      "[Calib 05/30] hp={'lr': 0.00033176857821930623, 'weight_decay': 0.00020076588824052998, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 12, 'fc_hidden': 16} CV_score=0.4136\n",
      "[Calib 06/30] hp={'lr': 0.004647656086274488, 'weight_decay': 0.00021269539109714837, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 12, 'fc_hidden': 32} CV_score=0.6837\n",
      "[Calib 07/30] hp={'lr': 0.005341651298995627, 'weight_decay': 0.0007449437976426804, 'batch_size': 128, 'num_kernels': 32, 'kernel_size': 36, 'fc_hidden': 32} CV_score=0.3086\n",
      "[Calib 08/30] hp={'lr': 0.0015772985722517822, 'weight_decay': 9.739420888806621e-05, 'batch_size': 128, 'num_kernels': 32, 'kernel_size': 24, 'fc_hidden': 64} CV_score=0.5831\n",
      "[Calib 09/30] hp={'lr': 0.0026661628807347314, 'weight_decay': 3.593346502356475e-05, 'batch_size': 64, 'num_kernels': 8, 'kernel_size': 12, 'fc_hidden': 64} CV_score=0.6192\n",
      "[Calib 10/30] hp={'lr': 0.0023769805760824663, 'weight_decay': 0.0003511023580320665, 'batch_size': 64, 'num_kernels': 8, 'kernel_size': 24, 'fc_hidden': 16} CV_score=0.4549\n",
      "[Calib 11/30] hp={'lr': 0.00012368161337495103, 'weight_decay': 0.00015173364795755857, 'batch_size': 128, 'num_kernels': 16, 'kernel_size': 36, 'fc_hidden': 64} CV_score=0.2862\n",
      "[Calib 12/30] hp={'lr': 0.0007913907027582119, 'weight_decay': 2.6490918743529007e-06, 'batch_size': 32, 'num_kernels': 8, 'kernel_size': 24, 'fc_hidden': 64} CV_score=0.4654\n",
      "[Calib 13/30] hp={'lr': 0.00017502377077962278, 'weight_decay': 1.001011840174777e-06, 'batch_size': 32, 'num_kernels': 8, 'kernel_size': 36, 'fc_hidden': 64} CV_score=0.2942\n",
      "[Calib 14/30] hp={'lr': 0.004913987321604735, 'weight_decay': 2.5901271687843103e-05, 'batch_size': 128, 'num_kernels': 8, 'kernel_size': 24, 'fc_hidden': 16} CV_score=0.5229\n",
      "[Calib 15/30] hp={'lr': 0.0001624604314606899, 'weight_decay': 0.00021231277458185453, 'batch_size': 32, 'num_kernels': 32, 'kernel_size': 24, 'fc_hidden': 16} CV_score=0.3388\n",
      "[Calib 16/30] hp={'lr': 0.0007282950199896928, 'weight_decay': 0.0007362322324976889, 'batch_size': 128, 'num_kernels': 8, 'kernel_size': 12, 'fc_hidden': 64} CV_score=0.4131\n",
      "[Calib 17/30] hp={'lr': 0.0006207188614500937, 'weight_decay': 1.0483286550691777e-06, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32} CV_score=0.3602\n",
      "[Calib 18/30] hp={'lr': 0.00021138219317552444, 'weight_decay': 1.9978815959194007e-06, 'batch_size': 64, 'num_kernels': 32, 'kernel_size': 36, 'fc_hidden': 16} CV_score=0.3003\n",
      "[Calib 19/30] hp={'lr': 0.0055142539807941935, 'weight_decay': 4.751888228582084e-05, 'batch_size': 128, 'num_kernels': 32, 'kernel_size': 12, 'fc_hidden': 32} CV_score=0.6926\n",
      "[Calib 20/30] hp={'lr': 0.0005909171277431364, 'weight_decay': 2.9297379760019996e-06, 'batch_size': 64, 'num_kernels': 32, 'kernel_size': 12, 'fc_hidden': 64} CV_score=0.6048\n",
      "[Calib 21/30] hp={'lr': 0.0017035276629276891, 'weight_decay': 6.355171735022163e-05, 'batch_size': 32, 'num_kernels': 32, 'kernel_size': 36, 'fc_hidden': 64} CV_score=0.3145\n",
      "[Calib 22/30] hp={'lr': 0.00023977362088476977, 'weight_decay': 5.260845546943905e-06, 'batch_size': 64, 'num_kernels': 8, 'kernel_size': 36, 'fc_hidden': 16} CV_score=0.2895\n",
      "[Calib 23/30] hp={'lr': 0.003570565833393906, 'weight_decay': 6.608576708078713e-05, 'batch_size': 128, 'num_kernels': 16, 'kernel_size': 12, 'fc_hidden': 16} CV_score=0.6358\n",
      "[Calib 24/30] hp={'lr': 0.0005212818427779389, 'weight_decay': 0.0008800482361357851, 'batch_size': 32, 'num_kernels': 8, 'kernel_size': 12, 'fc_hidden': 16} CV_score=0.4505\n",
      "[Calib 25/30] hp={'lr': 0.00242054779672201, 'weight_decay': 3.273349358296441e-06, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 16} CV_score=0.5552\n",
      "[Calib 26/30] hp={'lr': 0.00026534238061019165, 'weight_decay': 0.0002736289828681929, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 12, 'fc_hidden': 16} CV_score=0.3279\n",
      "[Calib 27/30] hp={'lr': 0.0011157930753148636, 'weight_decay': 0.00044928633179649265, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 12, 'fc_hidden': 16} CV_score=0.5831\n",
      "[Calib 28/30] hp={'lr': 0.002390115595364304, 'weight_decay': 8.126906675789963e-06, 'batch_size': 128, 'num_kernels': 32, 'kernel_size': 36, 'fc_hidden': 64} CV_score=0.3107\n",
      "[Calib 29/30] hp={'lr': 0.002056311474579002, 'weight_decay': 1.3766554826444113e-05, 'batch_size': 32, 'num_kernels': 16, 'kernel_size': 24, 'fc_hidden': 32} CV_score=0.6155\n",
      "[Calib 30/30] hp={'lr': 0.0015111447779297615, 'weight_decay': 0.00020989014861918349, 'batch_size': 128, 'num_kernels': 32, 'kernel_size': 12, 'fc_hidden': 32} CV_score=0.6377\n",
      "Best hyperparams: {'lr': 0.0055142539807941935, 'weight_decay': 4.751888228582084e-05, 'batch_size': 128, 'num_kernels': 32, 'kernel_size': 12, 'fc_hidden': 32} with CV score 0.6926\n",
      "[Train] Epoch01 loss=0.6638\n",
      "[Train] Epoch02 loss=0.5182\n",
      "[Train] Epoch03 loss=0.4738\n",
      "[Train] Epoch04 loss=0.4470\n",
      "[Train] Epoch05 loss=0.4322\n",
      "[Train] Epoch06 loss=0.4159\n",
      "[Train] Epoch07 loss=0.3900\n",
      "[Train] Epoch08 loss=0.3919\n",
      "[Train] Epoch09 loss=0.3770\n",
      "[Train] Epoch10 loss=0.3692\n",
      "[Train] Epoch11 loss=0.3856\n",
      "[Train] Epoch12 loss=0.3787\n",
      "[Train] Epoch13 loss=0.3621\n",
      "[Train] Epoch14 loss=0.3632\n",
      "[Train] Epoch15 loss=0.3535\n",
      "[Train] Epoch16 loss=0.3545\n",
      "[Train] Epoch17 loss=0.3530\n",
      "[Train] Epoch18 loss=0.3489\n",
      "[Train] Epoch19 loss=0.3443\n",
      "[Train] Epoch20 loss=0.3371\n",
      ">> Test Pearson: 0.7619\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python train.py \\\n",
    "  --data_type PBM \\\n",
    "  --seq_file ../DeepBind/data/dream5/pbm/sequences.tsv.gz \\\n",
    "  --tgt_file ../DeepBind/data/dream5/pbm/targets.tsv.gz \\\n",
    "  --tf_col TF_1 \\\n",
    "  --max_len 36 \\\n",
    "  --epochs 20 \\\n",
    "  --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d857719",
   "metadata": {},
   "source": [
    "使用文章里面推荐的超参数采样方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4f48af",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Calib 01/30] hp={'lr': 0.0024657439749198296, 'weight_decay': 1.6606963364231383e-10, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.7985\n",
      "[Calib 02/30] hp={'lr': 0.0015281954376632535, 'weight_decay': 3.340611409404236e-05, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 64} CV_score=0.7690\n",
      "[Calib 03/30] hp={'lr': 0.0028940286333845517, 'weight_decay': 0.0002971700846927089, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.7954\n",
      "[Calib 04/30] hp={'lr': 0.03387200383942684, 'weight_decay': 1.7769653136474043e-08, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.5323\n",
      "[Calib 05/30] hp={'lr': 0.024063648319758532, 'weight_decay': 5.374363135264486e-07, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.6749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syl/TFBS_prediction/my_repro/train.py:104: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  metrics.append(pearsonr(logits, labels)[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Calib 06/30] hp={'lr': 0.043598211480921134, 'weight_decay': 2.6336348308598094e-08, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 64} CV_score=nan\n",
      "[Calib 07/30] hp={'lr': 0.0007967778864187729, 'weight_decay': 5.469358463508562e-10, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.6352\n",
      "[Calib 08/30] hp={'lr': 0.0033936083208001605, 'weight_decay': 1.638609102619102e-05, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.7943\n",
      "[Calib 09/30] hp={'lr': 0.0012194245506612484, 'weight_decay': 1.3593557516519648e-06, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 64} CV_score=0.7518\n",
      "[Calib 10/30] hp={'lr': 0.02555887287373827, 'weight_decay': 0.0007224342252935954, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 64} CV_score=0.5766\n",
      "[Calib 11/30] hp={'lr': 0.026478229790624384, 'weight_decay': 1.965103064448779e-08, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 64} CV_score=nan\n",
      "[Calib 12/30] hp={'lr': 0.030968580590360437, 'weight_decay': 3.7335581690537492e-06, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 64} CV_score=nan\n",
      "[Calib 13/30] hp={'lr': 0.032697713579689924, 'weight_decay': 5.306224680072686e-06, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 16} CV_score=nan\n",
      "[Calib 14/30] hp={'lr': 0.04451859381046925, 'weight_decay': 0.00010380338525608387, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 16} CV_score=nan\n",
      "[Calib 15/30] hp={'lr': 0.010630459965425164, 'weight_decay': 2.3615881064769577e-05, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 16} CV_score=0.7671\n",
      "[Calib 16/30] hp={'lr': 0.024960605533369935, 'weight_decay': 9.950630620800633e-08, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.6722\n",
      "[Calib 17/30] hp={'lr': 0.025220522837981603, 'weight_decay': 5.347754572784492e-07, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 16} CV_score=0.6929\n",
      "[Calib 18/30] hp={'lr': 0.01766941786893834, 'weight_decay': 8.181012756762199e-08, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 64} CV_score=0.6225\n",
      "[Calib 19/30] hp={'lr': 0.0015418456268463333, 'weight_decay': 2.774502161976038e-10, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.7653\n",
      "[Calib 20/30] hp={'lr': 0.003230490379895539, 'weight_decay': 2.711222322721641e-09, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 16} CV_score=0.7717\n",
      "[Calib 21/30] hp={'lr': 0.002606213229470467, 'weight_decay': 1.1287025481060126e-09, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.7831\n",
      "[Calib 22/30] hp={'lr': 0.016362098188198265, 'weight_decay': 1.0928704933923229e-10, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 64} CV_score=0.6158\n",
      "[Calib 23/30] hp={'lr': 0.04623921071633695, 'weight_decay': 1.4409259894260535e-06, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.3754\n",
      "[Calib 24/30] hp={'lr': 0.0009715108952034202, 'weight_decay': 8.037967903572862e-05, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 16} CV_score=0.6270\n",
      "[Calib 25/30] hp={'lr': 0.001436343436816141, 'weight_decay': 6.681086072908261e-10, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 16} CV_score=0.6949\n",
      "[Calib 26/30] hp={'lr': 0.002411805831311796, 'weight_decay': 7.191457101023936e-10, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 16} CV_score=0.7857\n",
      "[Calib 27/30] hp={'lr': 0.0032623538816011037, 'weight_decay': 2.4146762620444688e-05, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 64} CV_score=0.7964\n",
      "[Calib 28/30] hp={'lr': 0.005448683073607825, 'weight_decay': 4.794128156809012e-10, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.7920\n",
      "[Calib 29/30] hp={'lr': 0.001915422027834147, 'weight_decay': 9.083336740420395e-09, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.7615\n",
      "[Calib 30/30] hp={'lr': 0.005992793252145229, 'weight_decay': 1.909535038178783e-10, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} CV_score=0.7695\n",
      "Best hyperparams: {'lr': 0.0024657439749198296, 'weight_decay': 1.6606963364231383e-10, 'batch_size': 64, 'num_kernels': 16, 'kernel_size': 16, 'fc_hidden': 32} with CV score 0.7985\n",
      "[Train] Epoch01 loss=0.7822\n",
      "[Train] Epoch02 loss=0.4295\n",
      "[Train] Epoch03 loss=0.3476\n",
      "[Train] Epoch04 loss=0.3231\n",
      "[Train] Epoch05 loss=0.3104\n",
      "[Train] Epoch06 loss=0.2969\n",
      "[Train] Epoch07 loss=0.2892\n",
      "[Train] Epoch08 loss=0.2820\n",
      "[Train] Epoch09 loss=0.2808\n",
      "[Train] Epoch10 loss=0.2787\n",
      "[Train] Epoch11 loss=0.2759\n",
      "[Train] Epoch12 loss=0.2744\n",
      "[Train] Epoch13 loss=0.2721\n",
      "[Train] Epoch14 loss=0.2693\n",
      "[Train] Epoch15 loss=0.2685\n",
      "[Train] Epoch16 loss=0.2697\n",
      "[Train] Epoch17 loss=0.2635\n",
      "[Train] Epoch18 loss=0.2595\n",
      "[Train] Epoch19 loss=0.2581\n",
      "[Train] Epoch20 loss=0.2598\n",
      ">> Test Pearson: 0.8530\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python train.py \\\n",
    "  --data_type PBM \\\n",
    "  --seq_file ../DeepBind/data/dream5/pbm/sequences.tsv.gz \\\n",
    "  --tgt_file ../DeepBind/data/dream5/pbm/targets.tsv.gz \\\n",
    "  --tf_col TF_2 \\\n",
    "  --max_len 36 \\\n",
    "  --epochs 20 \\\n",
    "  --device cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b902c7ae",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e5a9111",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a2f28d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on TF_23_CHIP_100_dinuc.seq ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/syl/TFBS_prediction/my_repro/train.py\", line 320, in <module>\n",
      "    main()\n",
      "  File \"/home/syl/TFBS_prediction/my_repro/train.py\", line 251, in main\n",
      "    score = cv_score(rest_ds, hp, device, binary=False)\n",
      "  File \"/home/syl/TFBS_prediction/my_repro/train.py\", line 148, in cv_score\n",
      "    model = DeepBind(\n",
      "  File \"/home/syl/anaconda3/envs/tfbs/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1369, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/syl/anaconda3/envs/tfbs/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 928, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/syl/anaconda3/envs/tfbs/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 955, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/syl/anaconda3/envs/tfbs/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1355, in convert\n",
      "    return t.to(\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while terminating subprocess (pid=84024): \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p out\n",
    "for f in ../DeepBind/data/dream5/chipseq/*.seq; do\n",
    "  base=$(basename \"$f\" .tsv)\n",
    "  echo \"Training on $base ...\"\n",
    "  python train.py --data_type ChIPSeq --seq_file \"$f\" --max_len 101 --epochs 10 --device cuda\n",
    "  mv deepbind.final.pth out/deepbind_${base}.pth\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb53ce",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'strings $(find $CONDA_PREFIX -name \"libstdc++.so.6\") | grep CXXABI\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstrings $(find $CONDA_PREFIX -name \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibstdc++.so.6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m) | grep CXXABI\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfbs/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2358\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2357\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2358\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/tfbs/lib/python3.9/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfbs/lib/python3.9/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'strings $(find $CONDA_PREFIX -name \"libstdc++.so.6\") | grep CXXABI\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "strings $(find $CONDA_PREFIX -name \"libstdc++.so.6\") | grep CXXABI\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfbs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
